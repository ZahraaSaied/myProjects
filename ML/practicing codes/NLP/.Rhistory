setwd("/media/zahraa/venus/@current work/Machine_Learning_A-Z_Hands-On_Python_and_R_In_Data_Science/my practice/NLP")
install.packages("tm")
setwd("/media/zahraa/venus/@current work/Machine_Learning_A-Z_Hands-On_Python_and_R_In_Data_Science/my practice/NLP")
install.packages("SnowballC")
original_dataset = read.delim("Restaurant_Reviews.tsv", quote = "", stringsAsFactors = FALSE)
View(original_dataset)
View(original_dataset)
library(tm)
library(SnowballC)
install.packages("tm")
install.packages("tm")
library(tm)
library(SnowballC)
library(tm)
library(SnowballC)
corpus = VCorpus(original_dataset$Review)
corpus = VCorpus(VectorSource(original_dataset$Review))
as.character(corpus[[1]])
corpus = tm_map(corpus, content_transformer(tolower))
as.character(corpus[[1]])
corpus = tm_map(corpus, removeNumbers)
corpus = tm_map(corpus, removePunctuation)
as.character(corpus[[1]])
corpus = tm_map(corpus, removeWhiteSpace)
corpus = tm_map(corpus, removeWords, stopwords)
corpus = tm_map(corpus, removeWords, stopwords())
as.character(corpus[[1]])
corpus = tm_map(corpus, stemDocument)
as.character(corpus[[1]])
corpus = tm_map(corpus, stripWhitespace)
corpus = tm_map(corpus, stripWhitespace)
as.character(corpus[[1]])
corpus = VCorpus(VectorSource(original_dataset$Review))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removeNumbers)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords())
corpus = tm_map(corpus, stemDocument)
corpus = tm_map(corpus, stripWhitespace)
dtm = DocumentTermMatrix(corpus)
dtm
View(original_dataset)
View(dtm)
dtm = removeSparseTerms(dtm, 0.9999)
View(dtm)
View(dtm)
# Create the bag of words
dtm = DocumentTermMatrix(corpus)
View(dtm)
dtm = removeSparseTerms(dtm, 0.999)
View(dtm)
dtm = removeSparseTerms(dtm, 0.9995)
View(dtm)
dtm = removeSparseTerms(dtm, 0.9998)
View(dtm)
View(dtm)
dtm = removeSparseTerms(dtm, 0.9999)
View(dtm)
dtm = removeSparseTerms(dtm, 0.999)
dataset = as.data.frame(as.matrix(dtm))
View(dataset)
dataset$Liked = original_dataset$Liked
library(caTools)
install.packages("caTools")
library(caTools)
library(caTools)
split = sample.split(dataset$Liked, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
dataset$Liked = factor(dataset$Liked, levels = c(0, 1))
library(caTools)
split = sample.split(dataset$Liked, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
install.packages("randomForest")
library(randomForest)
# Build the classification model
library(randomForest)
classifier = randomForest(x = dataset[-692],
y = dataset$Liked,
ntree = 10)
y_pred = predict(classifier, test_set[-692])
cm = table(test_set[-692], y_pred)
cm = table(test_set[692], y_pred)
cm = table(test_set[, 692], y_pred)
cm
original_dataset = read.delim("Restaurant_Reviews.tsv", quote = "", stringsAsFactors = FALSE)
# Clean the data
library(tm)
library(SnowballC)
corpus = VCorpus(VectorSource(original_dataset$Review))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removeNumbers)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords())
corpus = tm_map(corpus, stemDocument)
corpus = tm_map(corpus, stripWhitespace)
dtm = DocumentTermMatrix(corpus)
dtm = removeSparseTerms(dtm, 0.999)
dtm
dataset = as.data.frame(as.matrix(dtm))
dataset$Liked = original_dataset$Liked
dataset$Liked = factor(dataset$Liked, levels = c(0, 1))
library(caTools)
split = sample.split(dataset$Liked, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
library(randomForest)
classifier = randomForest(x = training_set[-692],
y = training_set$Liked,
ntree = 10)
# Predict the test set results
y_pred = predict(classifier, newdata = test_set[-692])
cm = table(test_set[, 692], y_pred)
cm
19 + 35
(81+65)/200
library(randomForest)
classifier = randomForest(x = training_set[-692],
y = training_set$Liked,
ntree = 20)
y_pred = predict(classifier, newdata = test_set[-692])
# Build the confusion matrix
cm = table(test_set[, 692], y_pred)
library(randomForest)
classifier = randomForest(x = training_set[-692],
y = training_set$Liked,
ntree = 50)
y_pred = predict(classifier, newdata = test_set[-692])
# Build the confusion matrix
cm = table(test_set[, 692], y_pred)
library(randomForest)
classifier = randomForest(x = training_set[-692],
y = training_set$Liked,
ntree = 50)
# Predict the test set results
y_pred = predict(classifier, newdata = test_set[-692])
# Build the confusion matrix
cm = table(test_set[, 692], y_pred)
library(randomForest)
classifier = randomForest(x = training_set[-692],
y = training_set$Liked,
ntree = 50)
# Predict the test set results
y_pred = predict(classifier, newdata = test_set[-692])
# Build the confusion matrix
cm = table(test_set[, 692], y_pred)
# Predict the test set results
y_pred = predict(classifier, newdata = test_set[-692])
# Build the confusion matrix
cm = table(test_set[, 692], y_pred)
library(randomForest)
classifier = randomForest(x = training_set[-692],
y = training_set$Liked,
ntree = 50)
y_pred = predict(classifier, newdata = test_set[-692])
# Build the confusion matrix
cm = table(test_set[, 692], y_pred)
(80+70)/200
